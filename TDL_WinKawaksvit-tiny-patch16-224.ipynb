{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5256696,"sourceType":"datasetVersion","datasetId":3041726}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import libraries, load and transform data","metadata":{}},{"cell_type":"code","source":"# Install necessary Python packages using pip\n\n# Use the 'pip' command to install packages\n# The '-q' flag stands for 'quiet,' which means it will suppress most output, making the installation process less verbose\n# We're installing the following packages:\n# - 'evaluate': This package is likely used for evaluation purposes, but the specific functionality is not clear from this line alone\n# - 'transformers': This package is commonly used for natural language processing tasks, such as working with pre-trained language models like BERT or GPT\n# - 'datasets': This package provides easy access to various datasets commonly used in machine learning and natural language processing tasks\n# - 'mlflow': MLflow is an open-source platform for managing the end-to-end machine learning lifecycle, including tracking experiments, packaging code into reproducible runs, and sharing and deploying models\n\n# Note: Before running this code, make sure you have Python and pip installed on your system.\n# Also, ensure you have an internet connection since pip will download and install these packages from PyPI (Python Package Index).\n!pip install -U -q evaluate transformers datasets>=2.14.5 accelerate>=0.27 mlflow 2>/dev/null","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:55:24.343058Z","iopub.execute_input":"2024-04-13T06:55:24.343380Z","iopub.status.idle":"2024-04-13T06:55:43.100345Z","shell.execute_reply.started":"2024-04-13T06:55:24.343354Z","shell.execute_reply":"2024-04-13T06:55:43.099159Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Importing necessary libraries and modules\nimport warnings  # Import the 'warnings' module for handling warnings\nwarnings.filterwarnings(\"ignore\")  # Ignore warnings during execution\n\nimport gc  # Import the 'gc' module for garbage collection\nimport numpy as np  # Import NumPy for numerical operations\nimport pandas as pd  # Import Pandas for data manipulation\nimport itertools  # Import 'itertools' for iterators and looping\nfrom collections import Counter  # Import 'Counter' for counting elements\nimport matplotlib.pyplot as plt  # Import Matplotlib for data visualization\nfrom sklearn.metrics import (  # Import various metrics from scikit-learn\n    accuracy_score,  # For calculating accuracy\n    roc_auc_score,  # For ROC AUC score\n    confusion_matrix,  # For confusion matrix\n    classification_report,  # For classification report\n    f1_score  # For F1 score\n)\n\n# Import custom modules and classes\nfrom imblearn.over_sampling import RandomOverSampler # import RandomOverSampler\nimport accelerate # Import the 'accelerate' module\nimport evaluate  # Import the 'evaluate' module\nfrom datasets import Dataset, Image, ClassLabel  # Import custom 'Dataset', 'ClassLabel', and 'Image' classes\nfrom transformers import (  # Import various modules from the Transformers library\n    TrainingArguments,  # For training arguments\n    Trainer,  # For model training\n    ViTImageProcessor,  # For processing image data with ViT models\n    ViTForImageClassification,  # ViT model for image classification\n    DefaultDataCollator  # For collating data in the default way\n)\nimport torch  # Import PyTorch for deep learning\nfrom torch.utils.data import DataLoader  # For creating data loaders\nfrom torchvision.transforms import (  # Import image transformation functions\n    CenterCrop,  # Center crop an image\n    Compose,  # Compose multiple image transformations\n    Normalize,  # Normalize image pixel values\n    RandomRotation,  # Apply random rotation to images\n    RandomResizedCrop,  # Crop and resize images randomly\n    RandomHorizontalFlip,  # Apply random horizontal flip\n    RandomAdjustSharpness,  # Adjust sharpness randomly\n    Resize,  # Resize images\n    ToTensor  # Convert images to PyTorch tensors\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:55:43.102402Z","iopub.execute_input":"2024-04-13T06:55:43.102675Z","iopub.status.idle":"2024-04-13T06:56:00.687107Z","shell.execute_reply.started":"2024-04-13T06:55:43.102649Z","shell.execute_reply":"2024-04-13T06:56:00.686357Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-04-13 06:55:52.653002: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-13 06:55:52.653094: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-13 06:55:52.758029: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import the necessary module from the Python Imaging Library (PIL).\nfrom PIL import ImageFile\n\n# Enable the option to load truncated images.\n# This setting allows the PIL library to attempt loading images even if they are corrupted or incomplete.\nImageFile.LOAD_TRUNCATED_IMAGES = True","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:56:00.688165Z","iopub.execute_input":"2024-04-13T06:56:00.688871Z","iopub.status.idle":"2024-04-13T06:56:00.693196Z","shell.execute_reply.started":"2024-04-13T06:56:00.688825Z","shell.execute_reply":"2024-04-13T06:56:00.692223Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# use https://huggingface.co/docs/datasets/image_load for reference\n\n# Import necessary libraries\nimage_dict = {}\n\n# Define the list of file names\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport os\n# Initialize empty lists to store file names and labels\nfile_names = []\nlabels = []\n\n# Iterate through all image files in the specified directory\nfor file in sorted((Path('/kaggle/input/cifake-real-and-ai-generated-synthetic-images/').glob('*/*/*.*'))):\n    label = str(file).split('/')[-2]  # Extract the label from the file path\n    labels.append(label)  # Add the label to the list\n    file_names.append(str(file))  # Add the file path to the list\n\n# Print the total number of file names and labels\nprint(len(file_names), len(labels))\n\n# Create a pandas dataframe from the collected file names and labels\ndf = pd.DataFrame.from_dict({\"image\": file_names, \"label\": labels})\nprint(df.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:56:14.807500Z","iopub.execute_input":"2024-04-13T06:56:14.808373Z","iopub.status.idle":"2024-04-13T06:56:20.237596Z","shell.execute_reply.started":"2024-04-13T06:56:14.808337Z","shell.execute_reply":"2024-04-13T06:56:20.236265Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"120000 120000\n(120000, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:03:39.672190Z","iopub.execute_input":"2024-04-13T08:03:39.672593Z","iopub.status.idle":"2024-04-13T08:03:39.683226Z","shell.execute_reply.started":"2024-04-13T08:03:39.672561Z","shell.execute_reply":"2024-04-13T08:03:39.682198Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"                                image label\n0  /kaggle/input/test/FAKE/0 (10).jpg  FAKE\n1   /kaggle/input/test/FAKE/0 (2).jpg  FAKE\n2   /kaggle/input/test/FAKE/0 (3).jpg  FAKE\n3   /kaggle/input/test/FAKE/0 (4).jpg  FAKE\n4   /kaggle/input/test/FAKE/0 (5).jpg  FAKE","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/test/FAKE/0 (10).jpg</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/test/FAKE/0 (2).jpg</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/test/FAKE/0 (3).jpg</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/test/FAKE/0 (4).jpg</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/test/FAKE/0 (5).jpg</td>\n      <td>FAKE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['label'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:03:41.762157Z","iopub.execute_input":"2024-04-13T08:03:41.762541Z","iopub.status.idle":"2024-04-13T08:03:41.777505Z","shell.execute_reply.started":"2024-04-13T08:03:41.762511Z","shell.execute_reply":"2024-04-13T08:03:41.776630Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"array(['FAKE', 'REAL'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"# random oversampling of minority class\n# 'y' contains the target variable (label) we want to predict\ny = df[['label']]\n\n# Drop the 'label' column from the DataFrame 'df' to separate features from the target variable\ndf = df.drop(['label'], axis=1)\n\n# Create a RandomOverSampler object with a specified random seed (random_state=83)\nros = RandomOverSampler(random_state=83)\n\n# Use the RandomOverSampler to resample the dataset by oversampling the minority class\n# 'df' contains the feature data, and 'y_resampled' will contain the resampled target variable\ndf, y_resampled = ros.fit_resample(df, y)\n\n# Delete the original 'y' variable to save memory as it's no longer needed\ndel y\n\n# Add the resampled target variable 'y_resampled' as a new 'label' column in the DataFrame 'df'\ndf['label'] = y_resampled\n\n# Delete the 'y_resampled' variable to save memory as it's no longer needed\ndel y_resampled\n\n# Perform garbage collection to free up memory used by discarded variables\ngc.collect()\n\nprint(df.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:56:30.791870Z","iopub.execute_input":"2024-04-13T06:56:30.792648Z","iopub.status.idle":"2024-04-13T06:56:31.786410Z","shell.execute_reply.started":"2024-04-13T06:56:30.792615Z","shell.execute_reply":"2024-04-13T06:56:31.785443Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"(120000, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a dataset from a Pandas DataFrame.\ndataset = Dataset.from_pandas(df).cast_column(\"image\", Image())","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:56:31.840864Z","iopub.execute_input":"2024-04-13T06:56:31.841418Z","iopub.status.idle":"2024-04-13T06:56:31.923532Z","shell.execute_reply.started":"2024-04-13T06:56:31.841390Z","shell.execute_reply":"2024-04-13T06:56:31.922778Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Display the first image in the dataset\ndataset[0][\"image\"]","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:56:32.631243Z","iopub.execute_input":"2024-04-13T06:56:32.631983Z","iopub.status.idle":"2024-04-13T06:56:32.660134Z","shell.execute_reply.started":"2024-04-13T06:56:32.631950Z","shell.execute_reply":"2024-04-13T06:56:32.659293Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=32x32>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# Extracting a subset of elements from the 'labels' list using slicing.\n# The slicing syntax [:5] selects elements from the beginning up to (but not including) the 5th element.\n# This will give us the first 5 elements of the 'labels' list.\n# The result will be a new list containing these elements.\nlabels_subset = labels[:5]\n\n# Printing the subset of labels to inspect the content.\nprint(labels_subset)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:56:34.766595Z","iopub.execute_input":"2024-04-13T06:56:34.767440Z","iopub.status.idle":"2024-04-13T06:56:34.772199Z","shell.execute_reply.started":"2024-04-13T06:56:34.767404Z","shell.execute_reply":"2024-04-13T06:56:34.771280Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"['FAKE', 'FAKE', 'FAKE', 'FAKE', 'FAKE']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a list of unique labels by converting 'labels' to a set and then back to a list\nlabels_list = ['REAL', 'FAKE'] #list(set(labels))\n\n# Initialize empty dictionaries to map labels to IDs and vice versa\nlabel2id, id2label = dict(), dict()\n\n# Iterate over the unique labels and assign each label an ID, and vice versa\nfor i, label in enumerate(labels_list):\n    label2id[label] = i  # Map the label to its corresponding ID\n    id2label[i] = label  # Map the ID to its corresponding label\n\n# Print the resulting dictionaries for reference\nprint(\"Mapping of IDs to Labels:\", id2label, '\\n')\nprint(\"Mapping of Labels to IDs:\", label2id)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:56:36.322311Z","iopub.execute_input":"2024-04-13T06:56:36.323092Z","iopub.status.idle":"2024-04-13T06:56:36.328693Z","shell.execute_reply.started":"2024-04-13T06:56:36.323059Z","shell.execute_reply":"2024-04-13T06:56:36.327820Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Mapping of IDs to Labels: {0: 'REAL', 1: 'FAKE'} \n\nMapping of Labels to IDs: {'REAL': 0, 'FAKE': 1}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Creating classlabels to match labels to IDs\nClassLabels = ClassLabel(num_classes=len(labels_list), names=labels_list)\n\n# Mapping labels to IDs\ndef map_label2id(example):\n    example['label'] = ClassLabels.str2int(example['label'])\n    return example\n\ndataset = dataset.map(map_label2id, batched=True)\n\n# Casting label column to ClassLabel Object\ndataset = dataset.cast_column('label', ClassLabels)\n\n# Splitting the dataset into training and testing sets using an 60-40 split ratio.\ndataset = dataset.train_test_split(test_size=0.4, shuffle=True, stratify_by_column=\"label\")\n\n# Extracting the training data from the split dataset.\ntrain_data = dataset['train']\n\n# Extracting the testing data from the split dataset.\ntest_data = dataset['test']","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:56:37.042106Z","iopub.execute_input":"2024-04-13T06:56:37.042911Z","iopub.status.idle":"2024-04-13T06:56:37.622362Z","shell.execute_reply.started":"2024-04-13T06:56:37.042878Z","shell.execute_reply":"2024-04-13T06:56:37.621629Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/120000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7841967f29634ad093fb1dd3de4809ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/120000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"072a9379a55c485dae93cb01bf7be29c"}},"metadata":{}}]},{"cell_type":"code","source":"# Define the pre-trained ViT model string\nmodel_str = \"WinKawaks/vit-tiny-patch16-224\" #'google/vit-base-patch16-224-in21k'\n\n# Create a processor for ViT model input from the pre-trained model\nprocessor = ViTImageProcessor.from_pretrained(model_str)\n\n# Retrieve the image mean and standard deviation used for normalization\nimage_mean, image_std = processor.image_mean, processor.image_std\n\n# Get the size (height) of the ViT model's input images\nsize = processor.size[\"height\"]\nprint(\"Size: \", size)\n\n# Define a normalization transformation for the input images\nnormalize = Normalize(mean=image_mean, std=image_std)\n\n# Define a set of transformations for training data\n_train_transforms = Compose(\n    [\n        Resize((size, size)),             # Resize images to the ViT model's input size\n        RandomRotation(90),               # Apply random rotation\n        RandomAdjustSharpness(2),         # Adjust sharpness randomly\n        ToTensor(),                       # Convert images to tensors\n        normalize                         # Normalize images using mean and std\n    ]\n)\n\n# Define a set of transformations for validation data\n_val_transforms = Compose(\n    [\n        Resize((size, size)),             # Resize images to the ViT model's input size\n        ToTensor(),                       # Convert images to tensors\n        normalize                         # Normalize images using mean and std\n    ]\n)\n\n# Define a function to apply training transformations to a batch of examples\ndef train_transforms(examples):\n    examples['pixel_values'] = [_train_transforms(image.convert(\"RGB\")) for image in examples['image']]\n    return examples\n\n# Define a function to apply validation transformations to a batch of examples\ndef val_transforms(examples):\n    examples['pixel_values'] = [_val_transforms(image.convert(\"RGB\")) for image in examples['image']]\n    return examples","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:56:38.732074Z","iopub.execute_input":"2024-04-13T06:56:38.732444Z","iopub.status.idle":"2024-04-13T06:56:38.911077Z","shell.execute_reply.started":"2024-04-13T06:56:38.732416Z","shell.execute_reply":"2024-04-13T06:56:38.910238Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fd7251057074ffb96e1ecf6df45137b"}},"metadata":{}},{"name":"stdout","text":"Size:  224\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set the transforms for the training data\ntrain_data.set_transform(train_transforms)\n\n# Set the transforms for the test/validation data\ntest_data.set_transform(val_transforms)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:56:40.981499Z","iopub.execute_input":"2024-04-13T06:56:40.982314Z","iopub.status.idle":"2024-04-13T06:56:40.994293Z","shell.execute_reply.started":"2024-04-13T06:56:40.982276Z","shell.execute_reply":"2024-04-13T06:56:40.993312Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Define a collate function that prepares batched data for model training.\ndef collate_fn(examples):\n    # Stack the pixel values from individual examples into a single tensor.\n    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n    \n    # Convert the label strings in examples to corresponding numeric IDs using label2id dictionary.\n    labels = torch.tensor([example['label'] for example in examples])\n    \n    # Return a dictionary containing the batched pixel values and labels.\n    return {\"pixel_values\": pixel_values, \"labels\": labels}","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:56:42.037295Z","iopub.execute_input":"2024-04-13T06:56:42.037950Z","iopub.status.idle":"2024-04-13T06:56:42.043043Z","shell.execute_reply.started":"2024-04-13T06:56:42.037918Z","shell.execute_reply":"2024-04-13T06:56:42.042095Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Load, train, and evaluate model","metadata":{}},{"cell_type":"code","source":"# Create a ViTForImageClassification model from a pretrained checkpoint with a specified number of output labels.\nmodel = ViTForImageClassification.from_pretrained(model_str, num_labels=len(labels_list),ignore_mismatched_sizes=True)\n\n# Configure the mapping of class labels to their corresponding indices for later reference.\nmodel.config.id2label = id2label\nmodel.config.label2id = label2id\n\n# Calculate and print the number of trainable parameters in millions for the model.\nprint(model.num_parameters(only_trainable=True) / 1e6)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:03:53.096420Z","iopub.execute_input":"2024-04-13T08:03:53.096769Z","iopub.status.idle":"2024-04-13T08:03:53.365726Z","shell.execute_reply.started":"2024-04-13T08:03:53.096740Z","shell.execute_reply":"2024-04-13T08:03:53.364861Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"Some weights of ViTForImageClassification were not initialized from the model checkpoint at WinKawaks/vit-tiny-patch16-224 and are newly initialized because the shapes did not match:\n- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n- classifier.weight: found shape torch.Size([1000, 192]) in the checkpoint and torch.Size([2, 192]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"5.524802\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the accuracy metric from a module named 'evaluate'\naccuracy = evaluate.load(\"accuracy\")\n\n# Define a function 'compute_metrics' to calculate evaluation metrics\ndef compute_metrics(eval_pred):\n    # Extract model predictions from the evaluation prediction object\n    predictions = eval_pred.predictions\n    \n    # Extract true labels from the evaluation prediction object\n    label_ids = eval_pred.label_ids\n    \n    # Calculate accuracy using the loaded accuracy metric\n    # Convert model predictions to class labels by selecting the class with the highest probability (argmax)\n    predicted_labels = predictions.argmax(axis=1)\n    \n    # Calculate accuracy score by comparing predicted labels to true labels\n    acc_score = accuracy.compute(predictions=predicted_labels, references=label_ids)['accuracy']\n    \n    # Return the computed accuracy as a dictionary with the key \"accuracy\"\n    return {\n        \"accuracy\": acc_score\n    }","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:56:48.022332Z","iopub.execute_input":"2024-04-13T06:56:48.023242Z","iopub.status.idle":"2024-04-13T06:56:48.427188Z","shell.execute_reply.started":"2024-04-13T06:56:48.023210Z","shell.execute_reply":"2024-04-13T06:56:48.426353Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcad01f465bf4936b180d9e0ee97b791"}},"metadata":{}}]},{"cell_type":"code","source":"# Define the name of the evaluation metric to be used during training and evaluation.\nmetric_name = \"accuracy\"\n\n# Define the name of the model, which will be used to create a directory for saving model checkpoints and outputs.\nmodel_name = \"ai_vs_real_image_detection\"\n\n# Define the number of training epochs for the model.\nnum_train_epochs = 2\n\n# Create an instance of TrainingArguments to configure training settings.\nargs = TrainingArguments(\n    # Specify the directory where model checkpoints and outputs will be saved.\n    output_dir=model_name,\n    \n    # Specify the directory where training logs will be stored.\n    logging_dir='./logs',\n    \n    # Define the evaluation strategy, which is performed at the end of each epoch.\n    evaluation_strategy=\"epoch\",\n    \n    # Set the learning rate for the optimizer.\n    learning_rate=1e-6,\n    \n    # Define the batch size for training on each device.\n    per_device_train_batch_size=64,\n    \n    # Define the batch size for evaluation on each device.\n    per_device_eval_batch_size=32,\n    \n    # Specify the total number of training epochs.\n    num_train_epochs=num_train_epochs,\n    \n    # Apply weight decay to prevent overfitting.\n    weight_decay=0.02,\n    \n    # Set the number of warm-up steps for the learning rate scheduler.\n    warmup_steps=50,\n    \n    # Disable the removal of unused columns from the dataset.\n    remove_unused_columns=False,\n    \n    # Define the strategy for saving model checkpoints (per epoch in this case).\n    save_strategy='epoch',\n    \n    # Load the best model at the end of training.\n    load_best_model_at_end=True,\n    \n    # Limit the total number of saved checkpoints to save space.\n    save_total_limit=1,\n    \n    # Specify that training progress should not be reported .\n    report_to=\"none\"  # log to none\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:56:49.066210Z","iopub.execute_input":"2024-04-13T06:56:49.066581Z","iopub.status.idle":"2024-04-13T06:56:49.175138Z","shell.execute_reply.started":"2024-04-13T06:56:49.066552Z","shell.execute_reply":"2024-04-13T06:56:49.174293Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Create a Trainer instance for fine-tuning a language model.\n\n# - `model`: The pre-trained language model to be fine-tuned.\n# - `args`: Configuration settings and hyperparameters for training.\n# - `train_dataset`: The dataset used for training the model.\n# - `eval_dataset`: The dataset used for evaluating the model during training.\n# - `data_collator`: A function that defines how data batches are collated and processed.\n# - `compute_metrics`: A function for computing custom evaluation metrics.\n# - `tokenizer`: The tokenizer used for processing text data.\n\ntrainer = Trainer(\n    model,\n    args,\n    train_dataset=train_data,\n    eval_dataset=test_data,\n    data_collator=collate_fn,\n    compute_metrics=compute_metrics,\n    tokenizer=processor,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:56:50.193087Z","iopub.execute_input":"2024-04-13T06:56:50.193915Z","iopub.status.idle":"2024-04-13T06:56:50.389239Z","shell.execute_reply.started":"2024-04-13T06:56:50.193881Z","shell.execute_reply":"2024-04-13T06:56:50.388476Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Evaluate the pre-training model's performance on a test dataset.\n# This function calculates various metrics such as accuracy, loss, etc.,\n# to assess how well the model is performing on unseen data.\n\ntrainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:57:13.656953Z","iopub.execute_input":"2024-04-13T06:57:13.657338Z","iopub.status.idle":"2024-04-13T07:05:07.129830Z","shell.execute_reply.started":"2024-04-13T06:57:13.657300Z","shell.execute_reply":"2024-04-13T07:05:07.128889Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1500' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [750/750 25:44]\n    </div>\n    "},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.8029435276985168,\n 'eval_accuracy': 0.519875,\n 'eval_runtime': 473.4667,\n 'eval_samples_per_second': 101.38,\n 'eval_steps_per_second': 1.584}"},"metadata":{}}]},{"cell_type":"code","source":"# Start training the model using the trainer object.\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-13T07:05:07.131746Z","iopub.execute_input":"2024-04-13T07:05:07.132021Z","iopub.status.idle":"2024-04-13T07:34:33.102485Z","shell.execute_reply.started":"2024-04-13T07:05:07.131998Z","shell.execute_reply":"2024-04-13T07:34:33.101667Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1126' max='1126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1126/1126 29:22, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.529600</td>\n      <td>0.690579</td>\n      <td>0.612229</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.301000</td>\n      <td>0.652813</td>\n      <td>0.640563</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1126, training_loss=0.400329511923646, metrics={'train_runtime': 1765.6679, 'train_samples_per_second': 81.556, 'train_steps_per_second': 0.638, 'total_flos': 7.18534709673984e+17, 'train_loss': 0.400329511923646, 'epoch': 2.0})"},"metadata":{}}]},{"cell_type":"code","source":"# Evaluate the post-training model's performance on the validation or test dataset.\n# This function computes various evaluation metrics like accuracy, loss, etc.\n# and provides insights into how well the model is performing.\n\ntrainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-04-13T07:34:33.103479Z","iopub.execute_input":"2024-04-13T07:34:33.103749Z","iopub.status.idle":"2024-04-13T07:37:37.129732Z","shell.execute_reply.started":"2024-04-13T07:34:33.103725Z","shell.execute_reply":"2024-04-13T07:37:37.128794Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [750/750 03:03]\n    </div>\n    "},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.6528134942054749,\n 'eval_accuracy': 0.6405625,\n 'eval_runtime': 184.0204,\n 'eval_samples_per_second': 260.841,\n 'eval_steps_per_second': 4.076,\n 'epoch': 2.0}"},"metadata":{}}]},{"cell_type":"code","source":"# Use the trained 'trainer' to make predictions on the 'test_data'.\noutputs = trainer.predict(test_data)\n\n# Print the metrics obtained from the prediction outputs.\nprint(outputs.metrics)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:04:04.066618Z","iopub.execute_input":"2024-04-13T08:04:04.067284Z","iopub.status.idle":"2024-04-13T08:07:49.502039Z","shell.execute_reply.started":"2024-04-13T08:04:04.067226Z","shell.execute_reply":"2024-04-13T08:07:49.501198Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"{'test_loss': 0.6528134942054749, 'test_accuracy': 0.6405625, 'test_runtime': 225.4289, 'test_samples_per_second': 212.927, 'test_steps_per_second': 3.327}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Extract the true labels from the model outputs\ny_true = outputs.label_ids\n\n# Predict the labels by selecting the class with the highest probability\ny_pred = outputs.predictions.argmax(1)\n\n# Define a function to plot a confusion matrix\ndef plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues, figsize=(10, 8)):\n    \"\"\"\n    This function plots a confusion matrix.\n\n    Parameters:\n        cm (array-like): Confusion matrix as returned by sklearn.metrics.confusion_matrix.\n        classes (list): List of class names, e.g., ['Class 0', 'Class 1'].\n        title (str): Title for the plot.\n        cmap (matplotlib colormap): Colormap for the plot.\n    \"\"\"\n    # Create a figure with a specified size\n    plt.figure(figsize=figsize)\n    \n    # Display the confusion matrix as an image with a colormap\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    # Define tick marks and labels for the classes on the axes\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.0f'\n    # Add text annotations to the plot indicating the values in the cells\n    thresh = cm.max() / 2.0\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    # Label the axes\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n    # Ensure the plot layout is tight\n    plt.tight_layout()\n    # Display the plot\n    plt.show()\n\n# Calculate accuracy and F1 score\naccuracy = accuracy_score(y_true, y_pred)\nf1 = f1_score(y_true, y_pred, average='macro')\n\n# Display accuracy and F1 score\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\n\n# Get the confusion matrix if there are a small number of labels\nif len(labels_list) <= 150:\n    # Compute the confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n\n    # Plot the confusion matrix using the defined function\n    plot_confusion_matrix(cm, labels_list, figsize=(8, 6))\n    \n# Finally, display classification report\nprint()\nprint(\"Classification report:\")\nprint()\nprint(classification_report(y_true, y_pred, target_names=labels_list, digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:07:49.504273Z","iopub.execute_input":"2024-04-13T08:07:49.504676Z","iopub.status.idle":"2024-04-13T08:07:49.896584Z","shell.execute_reply.started":"2024-04-13T08:07:49.504643Z","shell.execute_reply":"2024-04-13T08:07:49.895402Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Accuracy: 0.6406\nF1 Score: 0.6308\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"\nClassification report:\n\n              precision    recall  f1-score   support\n\n        REAL     0.7081    0.4783    0.5709     24000\n        FAKE     0.6061    0.8029    0.6908     24000\n\n    accuracy                         0.6406     48000\n   macro avg     0.6571    0.6406    0.6308     48000\nweighted avg     0.6571    0.6406    0.6308     48000\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the trained model: This line of code is responsible for saving the model\n# that has been trained using the trainer object. It will serialize the model\n# and its associated weights, making it possible to reload and use the model\n# in the future without the need to retrain it.\ntrainer.save_model()","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:07:49.898035Z","iopub.execute_input":"2024-04-13T08:07:49.898378Z","iopub.status.idle":"2024-04-13T08:07:49.959681Z","shell.execute_reply.started":"2024-04-13T08:07:49.898350Z","shell.execute_reply":"2024-04-13T08:07:49.958727Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Import the 'pipeline' function from the 'transformers' library.\nfrom transformers import pipeline\n\n# Create a pipeline for image classification tasks. \n# You need to specify the 'model_name' and the 'device' to use for inference.\n# - 'model_name': The name of the pre-trained model to be used for image classification.\n# - 'device': Specifies the device to use for running the model (0 for GPU, -1 for CPU).\npipe = pipeline('image-classification', model=model_name, device=0)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:07:49.962091Z","iopub.execute_input":"2024-04-13T08:07:49.962570Z","iopub.status.idle":"2024-04-13T08:07:50.876273Z","shell.execute_reply.started":"2024-04-13T08:07:49.962516Z","shell.execute_reply":"2024-04-13T08:07:50.875516Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Accessing an image from the 'test_data' dataset using index 1.\nimage = test_data[1][\"image\"]\n\n# Displaying the 'image' variable.\nimage","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:07:50.877224Z","iopub.execute_input":"2024-04-13T08:07:50.877490Z","iopub.status.idle":"2024-04-13T08:07:50.888622Z","shell.execute_reply.started":"2024-04-13T08:07:50.877467Z","shell.execute_reply":"2024-04-13T08:07:50.887680Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=32x32>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# Apply the 'pipe' function to process the 'image' variable.\npipe(image)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:07:50.889689Z","iopub.execute_input":"2024-04-13T08:07:50.889976Z","iopub.status.idle":"2024-04-13T08:07:50.949926Z","shell.execute_reply.started":"2024-04-13T08:07:50.889951Z","shell.execute_reply":"2024-04-13T08:07:50.949109Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"[{'label': 'REAL', 'score': 0.5070850253105164},\n {'label': 'FAKE', 'score': 0.49291500449180603}]"},"metadata":{}}]},{"cell_type":"code","source":"# This line of code accesses the \"label\" attribute of a specific element in the test_data list.\n# It's used to retrieve the actual label associated with a test data point.\nid2label[test_data[1][\"label\"]]","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:07:50.951145Z","iopub.execute_input":"2024-04-13T08:07:50.951578Z","iopub.status.idle":"2024-04-13T08:07:50.960137Z","shell.execute_reply.started":"2024-04-13T08:07:50.951546Z","shell.execute_reply":"2024-04-13T08:07:50.959148Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"'REAL'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Send model to Huggingface","metadata":{}},{"cell_type":"code","source":"# Import the necessary module to interact with the Hugging Face Hub.\nfrom huggingface_hub import notebook_login\n\n# Perform a login to the Hugging Face Hub.\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T10:21:31.594499Z","iopub.execute_input":"2024-04-06T10:21:31.594979Z","iopub.status.idle":"2024-04-06T10:21:31.620896Z","shell.execute_reply.started":"2024-04-06T10:21:31.594942Z","shell.execute_reply":"2024-04-06T10:21:31.62005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import the HfApi class from the huggingface_hub library.\nfrom huggingface_hub import HfApi\n\n# Create an instance of the HfApi class.\napi = HfApi()\n\n# Define the repository ID by combining the username \"dima806\" with the model name.\nrepo_id = f\"dima806/{model_name}\"\n\ntry:\n    # Attempt to create a new repository on the Hugging Face Model Hub using the specified repo_id.\n    api.create_repo(repo_id)\n    \n    # If the repository creation is successful, print a message indicating that the repository was created.\n    print(f\"Repo {repo_id} created\")\nexcept:\n    # If an exception is raised, print a message indicating that the repository already exists.\n    print(f\"Repo {repo_id} already exists\")","metadata":{"execution":{"iopub.status.busy":"2024-04-06T10:21:50.066521Z","iopub.execute_input":"2024-04-06T10:21:50.067246Z","iopub.status.idle":"2024-04-06T10:21:50.165731Z","shell.execute_reply.started":"2024-04-06T10:21:50.067209Z","shell.execute_reply":"2024-04-06T10:21:50.164876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Uploading a folder to the Hugging Face Model Hub\napi.upload_folder(\n    folder_path=model_name,  # The path to the folder to be uploaded\n    path_in_repo=\".\",  # The path where the folder will be stored in the repository\n    repo_id=repo_id,  # The ID of the repository where the folder will be uploaded\n    repo_type=\"model\",  # The type of the repository (in this case, a model repository)\n    revision=\"main\" # Revision name\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T10:21:50.510138Z","iopub.execute_input":"2024-04-06T10:21:50.510492Z","iopub.status.idle":"2024-04-06T10:22:21.116607Z","shell.execute_reply.started":"2024-04-06T10:21:50.510461Z","shell.execute_reply":"2024-04-06T10:22:21.115686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"hello\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}