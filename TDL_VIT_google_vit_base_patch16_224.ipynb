{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5256696,"sourceType":"datasetVersion","datasetId":3041726}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import libraries, load and transform data","metadata":{}},{"cell_type":"code","source":"# Install necessary Python packages using pip\n\n# Use the 'pip' command to install packages\n# The '-q' flag stands for 'quiet,' which means it will suppress most output, making the installation process less verbose\n# We're installing the following packages:\n# - 'evaluate': This package is likely used for evaluation purposes, but the specific functionality is not clear from this line alone\n# - 'transformers': This package is commonly used for natural language processing tasks, such as working with pre-trained language models like BERT or GPT\n# - 'datasets': This package provides easy access to various datasets commonly used in machine learning and natural language processing tasks\n# - 'mlflow': MLflow is an open-source platform for managing the end-to-end machine learning lifecycle, including tracking experiments, packaging code into reproducible runs, and sharing and deploying models\n\n# Note: Before running this code, make sure you have Python and pip installed on your system.\n# Also, ensure you have an internet connection since pip will download and install these packages from PyPI (Python Package Index).\n!pip install -U -q evaluate transformers datasets>=2.14.5 accelerate>=0.27 mlflow 2>/dev/null","metadata":{"execution":{"iopub.status.busy":"2024-04-13T04:45:46.649369Z","iopub.execute_input":"2024-04-13T04:45:46.650015Z","iopub.status.idle":"2024-04-13T04:46:00.071092Z","shell.execute_reply.started":"2024-04-13T04:45:46.649978Z","shell.execute_reply":"2024-04-13T04:46:00.069817Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Importing necessary libraries and modules\nimport warnings  # Import the 'warnings' module for handling warnings\nwarnings.filterwarnings(\"ignore\")  # Ignore warnings during execution\n\nimport gc  # Import the 'gc' module for garbage collection\nimport numpy as np  # Import NumPy for numerical operations\nimport pandas as pd  # Import Pandas for data manipulation\nimport itertools  # Import 'itertools' for iterators and looping\nfrom collections import Counter  # Import 'Counter' for counting elements\nimport matplotlib.pyplot as plt  # Import Matplotlib for data visualization\nfrom sklearn.metrics import (  # Import various metrics from scikit-learn\n    accuracy_score,  # For calculating accuracy\n    roc_auc_score,  # For ROC AUC score\n    confusion_matrix,  # For confusion matrix\n    classification_report,  # For classification report\n    f1_score  # For F1 score\n)\n\n# Import custom modules and classes\nfrom imblearn.over_sampling import RandomOverSampler # import RandomOverSampler\nimport accelerate # Import the 'accelerate' module\nimport evaluate  # Import the 'evaluate' module\nfrom datasets import Dataset, Image, ClassLabel  # Import custom 'Dataset', 'ClassLabel', and 'Image' classes\nfrom transformers import (  # Import various modules from the Transformers library\n    TrainingArguments,  # For training arguments\n    Trainer,  # For model training\n    ViTImageProcessor,  # For processing image data with ViT models\n    ViTForImageClassification,  # ViT model for image classification\n    DefaultDataCollator  # For collating data in the default way\n)\nimport torch  # Import PyTorch for deep learning\nfrom torch.utils.data import DataLoader  # For creating data loaders\nfrom torchvision.transforms import (  # Import image transformation functions\n    CenterCrop,  # Center crop an image\n    Compose,  # Compose multiple image transformations\n    Normalize,  # Normalize image pixel values\n    RandomRotation,  # Apply random rotation to images\n    RandomResizedCrop,  # Crop and resize images randomly\n    RandomHorizontalFlip,  # Apply random horizontal flip\n    RandomAdjustSharpness,  # Adjust sharpness randomly\n    Resize,  # Resize images\n    ToTensor  # Convert images to PyTorch tensors\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T04:46:00.073118Z","iopub.execute_input":"2024-04-13T04:46:00.073446Z","iopub.status.idle":"2024-04-13T04:46:00.083112Z","shell.execute_reply.started":"2024-04-13T04:46:00.073416Z","shell.execute_reply":"2024-04-13T04:46:00.082214Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import os\nprint(os.listdir(\"../input\"))","metadata":{"execution":{"iopub.status.busy":"2024-04-13T04:48:36.468621Z","iopub.execute_input":"2024-04-13T04:48:36.468999Z","iopub.status.idle":"2024-04-13T04:48:36.479472Z","shell.execute_reply.started":"2024-04-13T04:48:36.468971Z","shell.execute_reply":"2024-04-13T04:48:36.478582Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"['test', 'train']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import the necessary module from the Python Imaging Library (PIL).\nfrom PIL import ImageFile\n\n# Enable the option to load truncated images.\n# This setting allows the PIL library to attempt loading images even if they are corrupted or incomplete.\nImageFile.LOAD_TRUNCATED_IMAGES = True","metadata":{"execution":{"iopub.status.busy":"2024-04-13T04:46:00.084181Z","iopub.execute_input":"2024-04-13T04:46:00.084451Z","iopub.status.idle":"2024-04-13T04:46:00.100681Z","shell.execute_reply.started":"2024-04-13T04:46:00.084428Z","shell.execute_reply":"2024-04-13T04:46:00.099960Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# use https://huggingface.co/docs/datasets/image_load for reference\n\n# Import necessary libraries\nimage_dict = {}\n\n# Define the list of file names\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport os\n# Initialize empty lists to store file names and labels\nfile_names = []\nlabels = []\n\n# Iterate through all image files in the specified directory\nfor file in sorted((Path('/kaggle/input/cifake-real-and-ai-generated-synthetic-images/').glob('*/*/*.*'))):\n    label = str(file).split('/')[-2]  # Extract the label from the file path\n    labels.append(label)  # Add the label to the list\n    file_names.append(str(file))  # Add the file path to the list\n\n# Print the total number of file names and labels\nprint(len(file_names), len(labels))\n\n# Create a pandas dataframe from the collected file names and labels\ndf = pd.DataFrame.from_dict({\"image\": file_names, \"label\": labels})\nprint(df.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T04:48:59.852988Z","iopub.execute_input":"2024-04-13T04:48:59.853696Z","iopub.status.idle":"2024-04-13T04:49:08.738828Z","shell.execute_reply.started":"2024-04-13T04:48:59.853665Z","shell.execute_reply":"2024-04-13T04:49:08.737917Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"120000 120000\n(120000, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-13T04:49:11.813258Z","iopub.execute_input":"2024-04-13T04:49:11.813633Z","iopub.status.idle":"2024-04-13T04:49:11.823277Z","shell.execute_reply.started":"2024-04-13T04:49:11.813604Z","shell.execute_reply":"2024-04-13T04:49:11.822415Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                                image label\n0  /kaggle/input/test/FAKE/0 (10).jpg  FAKE\n1   /kaggle/input/test/FAKE/0 (2).jpg  FAKE\n2   /kaggle/input/test/FAKE/0 (3).jpg  FAKE\n3   /kaggle/input/test/FAKE/0 (4).jpg  FAKE\n4   /kaggle/input/test/FAKE/0 (5).jpg  FAKE","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/test/FAKE/0 (10).jpg</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/test/FAKE/0 (2).jpg</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/test/FAKE/0 (3).jpg</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/test/FAKE/0 (4).jpg</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/test/FAKE/0 (5).jpg</td>\n      <td>FAKE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['label'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-04-13T04:49:44.158926Z","iopub.execute_input":"2024-04-13T04:49:44.159342Z","iopub.status.idle":"2024-04-13T04:49:44.181762Z","shell.execute_reply.started":"2024-04-13T04:49:44.159311Z","shell.execute_reply":"2024-04-13T04:49:44.180767Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"array(['FAKE', 'REAL'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"# random oversampling of minority class\n# 'y' contains the target variable (label) we want to predict\ny = df[['label']]\n\n# Drop the 'label' column from the DataFrame 'df' to separate features from the target variable\ndf = df.drop(['label'], axis=1)\n\n# Create a RandomOverSampler object with a specified random seed (random_state=83)\nros = RandomOverSampler(random_state=83)\n\n# Use the RandomOverSampler to resample the dataset by oversampling the minority class\n# 'df' contains the feature data, and 'y_resampled' will contain the resampled target variable\ndf, y_resampled = ros.fit_resample(df, y)\n\n# Delete the original 'y' variable to save memory as it's no longer needed\ndel y\n\n# Add the resampled target variable 'y_resampled' as a new 'label' column in the DataFrame 'df'\ndf['label'] = y_resampled\n\n# Delete the 'y_resampled' variable to save memory as it's no longer needed\ndel y_resampled\n\n# Perform garbage collection to free up memory used by discarded variables\ngc.collect()\n\nprint(df.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T04:49:45.728692Z","iopub.execute_input":"2024-04-13T04:49:45.729586Z","iopub.status.idle":"2024-04-13T04:49:46.772833Z","shell.execute_reply.started":"2024-04-13T04:49:45.729546Z","shell.execute_reply":"2024-04-13T04:49:46.771970Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"(120000, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a dataset from a Pandas DataFrame.\ndataset = Dataset.from_pandas(df).cast_column(\"image\", Image())","metadata":{"execution":{"iopub.status.busy":"2024-04-13T04:49:46.948546Z","iopub.execute_input":"2024-04-13T04:49:46.948886Z","iopub.status.idle":"2024-04-13T04:49:47.066673Z","shell.execute_reply.started":"2024-04-13T04:49:46.948860Z","shell.execute_reply":"2024-04-13T04:49:47.065677Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Display the first image in the dataset\ndataset[0][\"image\"]","metadata":{"execution":{"iopub.status.busy":"2024-04-13T04:49:49.048617Z","iopub.execute_input":"2024-04-13T04:49:49.049547Z","iopub.status.idle":"2024-04-13T04:49:49.096343Z","shell.execute_reply.started":"2024-04-13T04:49:49.049510Z","shell.execute_reply":"2024-04-13T04:49:49.095428Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=32x32>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# Extracting a subset of elements from the 'labels' list using slicing.\n# The slicing syntax [:5] selects elements from the beginning up to (but not including) the 5th element.\n# This will give us the first 5 elements of the 'labels' list.\n# The result will be a new list containing these elements.\nlabels_subset = labels[:5]\n\n# Printing the subset of labels to inspect the content.\nprint(labels_subset)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T04:49:50.973687Z","iopub.execute_input":"2024-04-13T04:49:50.974075Z","iopub.status.idle":"2024-04-13T04:49:50.979321Z","shell.execute_reply.started":"2024-04-13T04:49:50.974045Z","shell.execute_reply":"2024-04-13T04:49:50.978289Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"['FAKE', 'FAKE', 'FAKE', 'FAKE', 'FAKE']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a list of unique labels by converting 'labels' to a set and then back to a list\nlabels_list = ['REAL', 'FAKE'] #list(set(labels))\n\n# Initialize empty dictionaries to map labels to IDs and vice versa\nlabel2id, id2label = dict(), dict()\n\n# Iterate over the unique labels and assign each label an ID, and vice versa\nfor i, label in enumerate(labels_list):\n    label2id[label] = i  # Map the label to its corresponding ID\n    id2label[i] = label  # Map the ID to its corresponding label\n\n# Print the resulting dictionaries for reference\nprint(\"Mapping of IDs to Labels:\", id2label, '\\n')\nprint(\"Mapping of Labels to IDs:\", label2id)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T04:49:52.148079Z","iopub.execute_input":"2024-04-13T04:49:52.148458Z","iopub.status.idle":"2024-04-13T04:49:52.154886Z","shell.execute_reply.started":"2024-04-13T04:49:52.148421Z","shell.execute_reply":"2024-04-13T04:49:52.154012Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Mapping of IDs to Labels: {0: 'REAL', 1: 'FAKE'} \n\nMapping of Labels to IDs: {'REAL': 0, 'FAKE': 1}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Creating classlabels to match labels to IDs\nClassLabels = ClassLabel(num_classes=len(labels_list), names=labels_list)\n\n# Mapping labels to IDs\ndef map_label2id(example):\n    example['label'] = ClassLabels.str2int(example['label'])\n    return example\n\ndataset = dataset.map(map_label2id, batched=True)\n\n# Casting label column to ClassLabel Object\ndataset = dataset.cast_column('label', ClassLabels)\n\n# Splitting the dataset into training and testing sets using an 60-40 split ratio.\ndataset = dataset.train_test_split(test_size=0.4, shuffle=True, stratify_by_column=\"label\")\n\n# Extracting the training data from the split dataset.\ntrain_data = dataset['train']\n\n# Extracting the testing data from the split dataset.\ntest_data = dataset['test']","metadata":{"execution":{"iopub.status.busy":"2024-04-13T04:49:52.603439Z","iopub.execute_input":"2024-04-13T04:49:52.603851Z","iopub.status.idle":"2024-04-13T04:49:53.196370Z","shell.execute_reply.started":"2024-04-13T04:49:52.603811Z","shell.execute_reply":"2024-04-13T04:49:53.195568Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/120000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"602658558d46480bb7339e65749df622"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/120000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2a8742c6b914ccc8b4693181805a59d"}},"metadata":{}}]},{"cell_type":"code","source":"# Define the pre-trained ViT model string\nmodel_str = \"google/vit-base-patch16-224\" #'google/vit-base-patch16-224-in21k'\n\n# Create a processor for ViT model input from the pre-trained model\nprocessor = ViTImageProcessor.from_pretrained(model_str)\n\n# Retrieve the image mean and standard deviation used for normalization\nimage_mean, image_std = processor.image_mean, processor.image_std\n\n# Get the size (height) of the ViT model's input images\nsize = processor.size[\"height\"]\nprint(\"Size: \", size)\n\n# Define a normalization transformation for the input images\nnormalize = Normalize(mean=image_mean, std=image_std)\n\n# Define a set of transformations for training data\n_train_transforms = Compose(\n    [\n        Resize((size, size)),             # Resize images to the ViT model's input size\n        RandomRotation(90),               # Apply random rotation\n        RandomAdjustSharpness(2),         # Adjust sharpness randomly\n        ToTensor(),                       # Convert images to tensors\n        normalize                         # Normalize images using mean and std\n    ]\n)\n\n# Define a set of transformations for validation data\n_val_transforms = Compose(\n    [\n        Resize((size, size)),             # Resize images to the ViT model's input size\n        ToTensor(),                       # Convert images to tensors\n        normalize                         # Normalize images using mean and std\n    ]\n)\n\n# Define a function to apply training transformations to a batch of examples\ndef train_transforms(examples):\n    examples['pixel_values'] = [_train_transforms(image.convert(\"RGB\")) for image in examples['image']]\n    return examples\n\n# Define a function to apply validation transformations to a batch of examples\ndef val_transforms(examples):\n    examples['pixel_values'] = [_val_transforms(image.convert(\"RGB\")) for image in examples['image']]\n    return examples","metadata":{"execution":{"iopub.status.busy":"2024-04-13T04:49:54.363398Z","iopub.execute_input":"2024-04-13T04:49:54.364245Z","iopub.status.idle":"2024-04-13T04:49:54.692622Z","shell.execute_reply.started":"2024-04-13T04:49:54.364210Z","shell.execute_reply":"2024-04-13T04:49:54.691771Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c54d334739944bd2b278a4f252bde956"}},"metadata":{}},{"name":"stdout","text":"Size:  224\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set the transforms for the training data\ntrain_data.set_transform(train_transforms)\n\n# Set the transforms for the test/validation data\ntest_data.set_transform(val_transforms)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T04:49:56.668126Z","iopub.execute_input":"2024-04-13T04:49:56.668979Z","iopub.status.idle":"2024-04-13T04:49:56.681498Z","shell.execute_reply.started":"2024-04-13T04:49:56.668945Z","shell.execute_reply":"2024-04-13T04:49:56.680585Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Define a collate function that prepares batched data for model training.\ndef collate_fn(examples):\n    # Stack the pixel values from individual examples into a single tensor.\n    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n    \n    # Convert the label strings in examples to corresponding numeric IDs using label2id dictionary.\n    labels = torch.tensor([example['label'] for example in examples])\n    \n    # Return a dictionary containing the batched pixel values and labels.\n    return {\"pixel_values\": pixel_values, \"labels\": labels}","metadata":{"execution":{"iopub.status.busy":"2024-04-13T04:49:58.008073Z","iopub.execute_input":"2024-04-13T04:49:58.008434Z","iopub.status.idle":"2024-04-13T04:49:58.013845Z","shell.execute_reply.started":"2024-04-13T04:49:58.008404Z","shell.execute_reply":"2024-04-13T04:49:58.012971Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# Load, train, and evaluate model","metadata":{}},{"cell_type":"code","source":"# Create a ViTForImageClassification model from a pretrained checkpoint with a specified number of output labels.\nmodel = ViTForImageClassification.from_pretrained(model_str, num_labels=len(labels_list),ignore_mismatched_sizes=True)\n\n# Configure the mapping of class labels to their corresponding indices for later reference.\nmodel.config.id2label = id2label\nmodel.config.label2id = label2id\n\n# Calculate and print the number of trainable parameters in millions for the model.\nprint(model.num_parameters(only_trainable=True) / 1e6)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T04:50:00.473775Z","iopub.execute_input":"2024-04-13T04:50:00.474526Z","iopub.status.idle":"2024-04-13T04:50:04.016113Z","shell.execute_reply.started":"2024-04-13T04:50:00.474496Z","shell.execute_reply":"2024-04-13T04:50:04.015188Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/69.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5a359f9f5194a78ae79fc14d3828e51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c666c8e0f73548fdb963713a6c54a714"}},"metadata":{}},{"name":"stderr","text":"Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"85.800194\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the accuracy metric from a module named 'evaluate'\naccuracy = evaluate.load(\"accuracy\")\n\n# Define a function 'compute_metrics' to calculate evaluation metrics\ndef compute_metrics(eval_pred):\n    # Extract model predictions from the evaluation prediction object\n    predictions = eval_pred.predictions\n    \n    # Extract true labels from the evaluation prediction object\n    label_ids = eval_pred.label_ids\n    \n    # Calculate accuracy using the loaded accuracy metric\n    # Convert model predictions to class labels by selecting the class with the highest probability (argmax)\n    predicted_labels = predictions.argmax(axis=1)\n    \n    # Calculate accuracy score by comparing predicted labels to true labels\n    acc_score = accuracy.compute(predictions=predicted_labels, references=label_ids)['accuracy']\n    \n    # Return the computed accuracy as a dictionary with the key \"accuracy\"\n    return {\n        \"accuracy\": acc_score\n    }","metadata":{"execution":{"iopub.status.busy":"2024-04-13T04:50:04.018009Z","iopub.execute_input":"2024-04-13T04:50:04.018613Z","iopub.status.idle":"2024-04-13T04:50:04.466124Z","shell.execute_reply.started":"2024-04-13T04:50:04.018577Z","shell.execute_reply":"2024-04-13T04:50:04.465286Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69dfb7aeb7da4f52bd0fc6bed91fe414"}},"metadata":{}}]},{"cell_type":"code","source":"# Define the name of the evaluation metric to be used during training and evaluation.\nmetric_name = \"accuracy\"\n\n# Define the name of the model, which will be used to create a directory for saving model checkpoints and outputs.\nmodel_name = \"ai_vs_real_image_detection\"\n\n# Define the number of training epochs for the model.\nnum_train_epochs = 2\n\n# Create an instance of TrainingArguments to configure training settings.\nargs = TrainingArguments(\n    # Specify the directory where model checkpoints and outputs will be saved.\n    output_dir=model_name,\n    \n    # Specify the directory where training logs will be stored.\n    logging_dir='./logs',\n    \n    # Define the evaluation strategy, which is performed at the end of each epoch.\n    evaluation_strategy=\"epoch\",\n    \n    # Set the learning rate for the optimizer.\n    learning_rate=1e-6,\n    \n    # Define the batch size for training on each device.\n    per_device_train_batch_size=64,\n    \n    # Define the batch size for evaluation on each device.\n    per_device_eval_batch_size=32,\n    \n    # Specify the total number of training epochs.\n    num_train_epochs=num_train_epochs,\n    \n    # Apply weight decay to prevent overfitting.\n    weight_decay=0.02,\n    \n    # Set the number of warm-up steps for the learning rate scheduler.\n    warmup_steps=50,\n    \n    # Disable the removal of unused columns from the dataset.\n    remove_unused_columns=False,\n    \n    # Define the strategy for saving model checkpoints (per epoch in this case).\n    save_strategy='epoch',\n    \n    # Load the best model at the end of training.\n    load_best_model_at_end=True,\n    \n    # Limit the total number of saved checkpoints to save space.\n    save_total_limit=1,\n    \n    # Specify that training progress should not be reported .\n    report_to=\"none\"  # log to none\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T04:50:06.613264Z","iopub.execute_input":"2024-04-13T04:50:06.613991Z","iopub.status.idle":"2024-04-13T04:50:06.725317Z","shell.execute_reply.started":"2024-04-13T04:50:06.613954Z","shell.execute_reply":"2024-04-13T04:50:06.724335Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Create a Trainer instance for fine-tuning a language model.\n\n# - `model`: The pre-trained language model to be fine-tuned.\n# - `args`: Configuration settings and hyperparameters for training.\n# - `train_dataset`: The dataset used for training the model.\n# - `eval_dataset`: The dataset used for evaluating the model during training.\n# - `data_collator`: A function that defines how data batches are collated and processed.\n# - `compute_metrics`: A function for computing custom evaluation metrics.\n# - `tokenizer`: The tokenizer used for processing text data.\n\ntrainer = Trainer(\n    model,\n    args,\n    train_dataset=train_data,\n    eval_dataset=test_data,\n    data_collator=collate_fn,\n    compute_metrics=compute_metrics,\n    tokenizer=processor,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T04:50:07.973083Z","iopub.execute_input":"2024-04-13T04:50:07.973813Z","iopub.status.idle":"2024-04-13T04:50:08.255094Z","shell.execute_reply.started":"2024-04-13T04:50:07.973780Z","shell.execute_reply":"2024-04-13T04:50:08.254092Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Evaluate the pre-training model's performance on a test dataset.\n# This function calculates various metrics such as accuracy, loss, etc.,\n# to assess how well the model is performing on unseen data.\n\ntrainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-04-13T04:50:09.408303Z","iopub.execute_input":"2024-04-13T04:50:09.408664Z","iopub.status.idle":"2024-04-13T05:05:01.278493Z","shell.execute_reply.started":"2024-04-13T04:50:09.408633Z","shell.execute_reply":"2024-04-13T05:05:01.277487Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1500' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [750/750 1:00:26]\n    </div>\n    "},"metadata":{}},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.8116520047187805,\n 'eval_accuracy': 0.5022916666666667,\n 'eval_runtime': 891.8635,\n 'eval_samples_per_second': 53.82,\n 'eval_steps_per_second': 0.841}"},"metadata":{}}]},{"cell_type":"code","source":"# Start training the model using the trainer object.\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-13T05:05:01.280528Z","iopub.execute_input":"2024-04-13T05:05:01.281298Z","iopub.status.idle":"2024-04-13T06:24:43.702265Z","shell.execute_reply.started":"2024-04-13T05:05:01.281261Z","shell.execute_reply":"2024-04-13T06:24:43.701305Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1126' max='1126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1126/1126 1:19:35, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.512000</td>\n      <td>0.680523</td>\n      <td>0.589604</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.301200</td>\n      <td>0.662823</td>\n      <td>0.605104</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1126, training_loss=0.39180006227103686, metrics={'train_runtime': 4782.0421, 'train_samples_per_second': 30.113, 'train_steps_per_second': 0.235, 'total_flos': 1.1158846504501248e+19, 'train_loss': 0.39180006227103686, 'epoch': 2.0})"},"metadata":{}}]},{"cell_type":"code","source":"# Evaluate the post-training model's performance on the validation or test dataset.\n# This function computes various evaluation metrics like accuracy, loss, etc.\n# and provides insights into how well the model is performing.\n\ntrainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:24:43.703921Z","iopub.execute_input":"2024-04-13T06:24:43.704204Z","iopub.status.idle":"2024-04-13T06:31:46.657627Z","shell.execute_reply.started":"2024-04-13T06:24:43.704179Z","shell.execute_reply":"2024-04-13T06:31:46.656633Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.6628230214118958,\n 'eval_accuracy': 0.6051041666666667,\n 'eval_runtime': 422.9476,\n 'eval_samples_per_second': 113.489,\n 'eval_steps_per_second': 1.773,\n 'epoch': 2.0}"},"metadata":{}}]},{"cell_type":"code","source":"# Use the trained 'trainer' to make predictions on the 'test_data'.\noutputs = trainer.predict(test_data)\n\n# Print the metrics obtained from the prediction outputs.\nprint(outputs.metrics)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:31:46.659521Z","iopub.execute_input":"2024-04-13T06:31:46.659895Z","iopub.status.idle":"2024-04-13T06:38:51.900175Z","shell.execute_reply.started":"2024-04-13T06:31:46.659861Z","shell.execute_reply":"2024-04-13T06:38:51.899262Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"{'test_loss': 0.6628230214118958, 'test_accuracy': 0.6051041666666667, 'test_runtime': 425.2337, 'test_samples_per_second': 112.879, 'test_steps_per_second': 1.764}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Extract the true labels from the model outputs\ny_true = outputs.label_ids\n\n# Predict the labels by selecting the class with the highest probability\ny_pred = outputs.predictions.argmax(1)\n\n# Define a function to plot a confusion matrix\ndef plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues, figsize=(10, 8)):\n    \"\"\"\n    This function plots a confusion matrix.\n\n    Parameters:\n        cm (array-like): Confusion matrix as returned by sklearn.metrics.confusion_matrix.\n        classes (list): List of class names, e.g., ['Class 0', 'Class 1'].\n        title (str): Title for the plot.\n        cmap (matplotlib colormap): Colormap for the plot.\n    \"\"\"\n    # Create a figure with a specified size\n    plt.figure(figsize=figsize)\n    \n    # Display the confusion matrix as an image with a colormap\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    # Define tick marks and labels for the classes on the axes\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.0f'\n    # Add text annotations to the plot indicating the values in the cells\n    thresh = cm.max() / 2.0\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    # Label the axes\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n    # Ensure the plot layout is tight\n    plt.tight_layout()\n    # Display the plot\n    plt.show()\n\n# Calculate accuracy and F1 score\naccuracy = accuracy_score(y_true, y_pred)\nf1 = f1_score(y_true, y_pred, average='macro')\n\n# Display accuracy and F1 score\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\n\n# Get the confusion matrix if there are a small number of labels\nif len(labels_list) <= 150:\n    # Compute the confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n\n    # Plot the confusion matrix using the defined function\n    plot_confusion_matrix(cm, labels_list, figsize=(8, 6))\n    \n# Finally, display classification report\nprint()\nprint(\"Classification report:\")\nprint()\nprint(classification_report(y_true, y_pred, target_names=labels_list, digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:38:51.901867Z","iopub.execute_input":"2024-04-13T06:38:51.902199Z","iopub.status.idle":"2024-04-13T06:38:52.356935Z","shell.execute_reply.started":"2024-04-13T06:38:51.902153Z","shell.execute_reply":"2024-04-13T06:38:52.355906Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Accuracy: 0.6051\nF1 Score: 0.5729\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"\nClassification report:\n\n              precision    recall  f1-score   support\n\n        REAL     0.5678    0.8797    0.6902     24000\n        FAKE     0.7331    0.3305    0.4556     24000\n\n    accuracy                         0.6051     48000\n   macro avg     0.6505    0.6051    0.5729     48000\nweighted avg     0.6505    0.6051    0.5729     48000\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the trained model: This line of code is responsible for saving the model\n# that has been trained using the trainer object. It will serialize the model\n# and its associated weights, making it possible to reload and use the model\n# in the future without the need to retrain it.\ntrainer.save_model()","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:38:52.358999Z","iopub.execute_input":"2024-04-13T06:38:52.359292Z","iopub.status.idle":"2024-04-13T06:38:52.890069Z","shell.execute_reply.started":"2024-04-13T06:38:52.359266Z","shell.execute_reply":"2024-04-13T06:38:52.889037Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Import the 'pipeline' function from the 'transformers' library.\nfrom transformers import pipeline\n\n# Create a pipeline for image classification tasks. \n# You need to specify the 'model_name' and the 'device' to use for inference.\n# - 'model_name': The name of the pre-trained model to be used for image classification.\n# - 'device': Specifies the device to use for running the model (0 for GPU, -1 for CPU).\npipe = pipeline('image-classification', model=model_name, device=0)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:38:52.891320Z","iopub.execute_input":"2024-04-13T06:38:52.891604Z","iopub.status.idle":"2024-04-13T06:38:54.418306Z","shell.execute_reply.started":"2024-04-13T06:38:52.891580Z","shell.execute_reply":"2024-04-13T06:38:54.417469Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# Accessing an image from the 'test_data' dataset using index 1.\nimage = test_data[1][\"image\"]\n\n# Displaying the 'image' variable.\nimage","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:38:54.419533Z","iopub.execute_input":"2024-04-13T06:38:54.419847Z","iopub.status.idle":"2024-04-13T06:38:54.429007Z","shell.execute_reply.started":"2024-04-13T06:38:54.419821Z","shell.execute_reply":"2024-04-13T06:38:54.428034Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=32x32>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# Apply the 'pipe' function to process the 'image' variable.\npipe(image)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:38:54.430110Z","iopub.execute_input":"2024-04-13T06:38:54.430379Z","iopub.status.idle":"2024-04-13T06:38:54.517439Z","shell.execute_reply.started":"2024-04-13T06:38:54.430356Z","shell.execute_reply":"2024-04-13T06:38:54.516537Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"[{'label': 'REAL', 'score': 0.5853961110115051},\n {'label': 'FAKE', 'score': 0.4146038889884949}]"},"metadata":{}}]},{"cell_type":"code","source":"# This line of code accesses the \"label\" attribute of a specific element in the test_data list.\n# It's used to retrieve the actual label associated with a test data point.\nid2label[test_data[1][\"label\"]]","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:38:54.518679Z","iopub.execute_input":"2024-04-13T06:38:54.519077Z","iopub.status.idle":"2024-04-13T06:38:54.530836Z","shell.execute_reply.started":"2024-04-13T06:38:54.519041Z","shell.execute_reply":"2024-04-13T06:38:54.529773Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"'FAKE'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Send model to Huggingface","metadata":{}},{"cell_type":"code","source":"# Import the necessary module to interact with the Hugging Face Hub.\nfrom huggingface_hub import notebook_login\n\n# Perform a login to the Hugging Face Hub.\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:38:54.532247Z","iopub.execute_input":"2024-04-13T06:38:54.532544Z","iopub.status.idle":"2024-04-13T06:38:54.567827Z","shell.execute_reply.started":"2024-04-13T06:38:54.532518Z","shell.execute_reply":"2024-04-13T06:38:54.566939Z"},"trusted":true},"execution_count":42,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ca4ed9017634c2daefd0ae41b069a98"}},"metadata":{}}]},{"cell_type":"code","source":"# Import the HfApi class from the huggingface_hub library.\nfrom huggingface_hub import HfApi\n\n# Create an instance of the HfApi class.\napi = HfApi()\n\n# Define the repository ID by combining the username \"dima806\" with the model name.\nrepo_id = f\"dima806/{model_name}\"\n\ntry:\n    # Attempt to create a new repository on the Hugging Face Model Hub using the specified repo_id.\n    api.create_repo(repo_id)\n    \n    # If the repository creation is successful, print a message indicating that the repository was created.\n    print(f\"Repo {repo_id} created\")\nexcept:\n    # If an exception is raised, print a message indicating that the repository already exists.\n    print(f\"Repo {repo_id} already exists\")","metadata":{"execution":{"iopub.status.busy":"2024-04-06T10:21:50.066521Z","iopub.execute_input":"2024-04-06T10:21:50.067246Z","iopub.status.idle":"2024-04-06T10:21:50.165731Z","shell.execute_reply.started":"2024-04-06T10:21:50.067209Z","shell.execute_reply":"2024-04-06T10:21:50.164876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Uploading a folder to the Hugging Face Model Hub\napi.upload_folder(\n    folder_path=model_name,  # The path to the folder to be uploaded\n    path_in_repo=\".\",  # The path where the folder will be stored in the repository\n    repo_id=repo_id,  # The ID of the repository where the folder will be uploaded\n    repo_type=\"model\",  # The type of the repository (in this case, a model repository)\n    revision=\"main\" # Revision name\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T10:21:50.510138Z","iopub.execute_input":"2024-04-06T10:21:50.510492Z","iopub.status.idle":"2024-04-06T10:22:21.116607Z","shell.execute_reply.started":"2024-04-06T10:21:50.510461Z","shell.execute_reply":"2024-04-06T10:22:21.115686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}