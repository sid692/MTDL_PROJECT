{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ME7J9FpcnnMG"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets --upgrade --quiet\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import opendatasets as od\n",
        "\n",
        "# Assign the Kaggle data set URL into variable\n",
        "dataset = 'https://www.kaggle.com/datasets/birdy654/cifake-real-and-ai-generated-synthetic-images'\n",
        "# Using opendatasets let's download the data sets\n",
        "od.download(dataset)\n",
        "# # {\"username\":\"kganeshv\",\"key\":\"224eab20b74a0a68fc7194190f513131\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StjlQKS9nnMJ"
      },
      "source": [
        "## Fine-tuning CNN for AI-generated Image Detection\n",
        "In this notebook, we will explore the task of classifying images as real or AI-generated using fine-tuning techniques with several well-known CNN architectures. For this classification task, we will use the CIFAKE dataset, which includes both real and AI-generated images.\n",
        "\n",
        "Link for the dataset: [CIFAKE: Real and AI-Generated Synthetic Images](https://www.kaggle.com/datasets/birdy654/cifake-real-and-ai-generated-synthetic-images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-31T16:35:51.73165Z",
          "iopub.status.busy": "2024-03-31T16:35:51.730678Z",
          "iopub.status.idle": "2024-03-31T16:36:08.578732Z",
          "shell.execute_reply": "2024-03-31T16:36:08.577764Z",
          "shell.execute_reply.started": "2024-03-31T16:35:51.731566Z"
        },
        "id": "qiffr4p2nnMK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras import regularizers\n",
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-31T16:36:08.582404Z",
          "iopub.status.busy": "2024-03-31T16:36:08.580757Z",
          "iopub.status.idle": "2024-03-31T16:36:08.591942Z",
          "shell.execute_reply": "2024-03-31T16:36:08.590772Z",
          "shell.execute_reply.started": "2024-03-31T16:36:08.582355Z"
        },
        "id": "rMp1xrTunnML",
        "outputId": "0592133d-5916-447c-f8c8-4c8435b9186c",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset from: /kaggle/input/cifake-real-and-ai-generated-synthetic-images/\n"
          ]
        }
      ],
      "source": [
        "dataset_dir = \"cifake-real-and-ai-generated-synthetic-images\" # For Kaggle notebooks. If you run locally, point this line to the CIFAKE directory\n",
        "print(\"Loading dataset from: \" + dataset_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-31T16:36:08.595138Z",
          "iopub.status.busy": "2024-03-31T16:36:08.594746Z",
          "iopub.status.idle": "2024-03-31T16:36:08.677438Z",
          "shell.execute_reply": "2024-03-31T16:36:08.676301Z",
          "shell.execute_reply.started": "2024-03-31T16:36:08.595107Z"
        },
        "id": "gmFwCQg1nnML",
        "outputId": "7074477e-a737-4824-b35f-9acd591e7ead",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "# Check if GPUs are available for training\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-31T16:36:33.551469Z",
          "iopub.status.busy": "2024-03-31T16:36:33.551033Z",
          "iopub.status.idle": "2024-03-31T16:37:50.587898Z",
          "shell.execute_reply": "2024-03-31T16:37:50.586825Z",
          "shell.execute_reply.started": "2024-03-31T16:36:33.551438Z"
        },
        "id": "QTOKpE-9nnMM",
        "outputId": "966b7b09-293e-4900-e958-ca8ada758b6c",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 100000 files belonging to 2 classes.\n",
            "Found 20000 files belonging to 2 classes.\n",
            "Training Classes:\n",
            "['FAKE', 'REAL']\n",
            "Testing Classes:\n",
            "['FAKE', 'REAL']\n"
          ]
        }
      ],
      "source": [
        "img_height = 32\n",
        "img_width = 32\n",
        "batch_size = 500\n",
        "\n",
        "# Load the training data\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  dataset_dir + \"/train\",\n",
        "  seed = 512,\n",
        "  image_size = (img_height, img_width),\n",
        "  batch_size = batch_size)\n",
        "\n",
        "# Load the validation data\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  dataset_dir + \"/test\",\n",
        "  seed = 512,\n",
        "  image_size = (img_height, img_width),\n",
        "  batch_size = batch_size)\n",
        "\n",
        "print(\"Training Classes:\")\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)\n",
        "\n",
        "print(\"Testing Classes:\")\n",
        "class_names = val_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxzW91_znnMM"
      },
      "source": [
        "Larger batch sizes are expected to result in significantly longer training times, especially with a substantial training set of 100,000 images. However, the compact size of the images effectively reduces the impact on training duration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-31T16:37:50.59046Z",
          "iopub.status.busy": "2024-03-31T16:37:50.590128Z",
          "iopub.status.idle": "2024-03-31T16:38:08.555265Z",
          "shell.execute_reply": "2024-03-31T16:38:08.554015Z",
          "shell.execute_reply.started": "2024-03-31T16:37:50.59043Z"
        },
        "id": "kbXwXnbFnnMM",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Function for plotting the error rate and metrics rate\n",
        "def plot_metrics(history, metric):\n",
        "    plt.plot(history.history[metric], label = metric)\n",
        "    plt.plot(history.history['val_' + metric], label='val_' + metric)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(metric)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Constant values that will be shared by all the models\n",
        "val_true_classes = np.concatenate([y for x, y in val_ds], axis = 0)  # Get true labels\n",
        "class_names = ['FAKE', 'REAL']\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 10, restore_best_weights = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWnLI28BnnMN"
      },
      "source": [
        "### Model Building\n",
        "\n",
        "All the models share the same architecture for a fair comparison: the input layer, followed by the base model with pre-trained weights from the imagenet, then a few dense layers, and then a unit output with a sigmoid activation function.\n",
        "\n",
        "Training is conducted with early stopping criteria monitoring the validation loss, and the best weights will be restored once the training is completed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-31T16:38:08.558375Z",
          "iopub.status.busy": "2024-03-31T16:38:08.557074Z",
          "iopub.status.idle": "2024-03-31T16:38:33.203372Z",
          "shell.execute_reply": "2024-03-31T16:38:33.20141Z",
          "shell.execute_reply.started": "2024-03-31T16:38:08.558335Z"
        },
        "id": "PXBuCt9TnnMN",
        "outputId": "b1d80b9a-da25-400c-f7f8-73064feae510",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "234545216/234545216 [==============================] - 11s 0us/step\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " resnet152v2 (Functional)    (None, 2048)              58331648  \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 2048)              8192      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               524544    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 58880897 (224.61 MB)\n",
            "Trainable params: 58733057 (224.05 MB)\n",
            "Non-trainable params: 147840 (577.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "Net_base_model = tf.keras.applications.ResNet152V2(\n",
        "    include_top = False,\n",
        "    weights = 'imagenet',\n",
        "    input_shape = (img_height, img_width, 3),\n",
        "    pooling = 'max'\n",
        ")\n",
        "Net_base_model.trainable = True\n",
        "\n",
        "\n",
        "inputs = tf.keras.Input(shape = (img_height, img_width, 3))\n",
        "x = Net_base_model(inputs, training = False)\n",
        "x = BatchNormalization(axis = -1, momentum = 0.99, epsilon = 0.001)(x)\n",
        "x = Dense(256,\n",
        "          kernel_regularizer = regularizers.l2(0.01),\n",
        "          activity_regularizer = regularizers.l1(0.01),\n",
        "          bias_regularizer = regularizers.l1(0.01),\n",
        "          activation = 'relu')(x)\n",
        "x = Dropout(rate = .4, seed = 512)(x)\n",
        "x = Dense(64, activation = 'relu')(x)\n",
        "outputs = Dense(1, activation = 'sigmoid')(x)\n",
        "Net_model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "Net_model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adamax(learning_rate = .001),\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics = ['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        ")\n",
        "\n",
        "# Summary of the model\n",
        "Net_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-01-31T05:05:50.096946Z",
          "iopub.status.busy": "2024-01-31T05:05:50.096562Z",
          "iopub.status.idle": "2024-01-31T05:17:39.998747Z",
          "shell.execute_reply": "2024-01-31T05:17:39.997713Z",
          "shell.execute_reply.started": "2024-01-31T05:05:50.096915Z"
        },
        "id": "2J9vPV-mnnMN",
        "outputId": "02aaffd9-aba4-4dfd-a03d-e54bb1aa4854",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training with Transfer Learning using ResNet50...\n",
            "Epoch 1/100\n",
            "200/200 [==============================] - 217s 399ms/step - loss: 2.4173 - accuracy: 0.8404 - precision_1: 0.8578 - recall_1: 0.8162 - val_loss: 1.6420 - val_accuracy: 0.5655 - val_precision_1: 0.9992 - val_recall_1: 0.1310\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - 79s 396ms/step - loss: 0.8672 - accuracy: 0.9218 - precision_1: 0.9209 - recall_1: 0.9227 - val_loss: 0.6610 - val_accuracy: 0.8966 - val_precision_1: 0.9755 - val_recall_1: 0.8136\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - 82s 409ms/step - loss: 0.4263 - accuracy: 0.9347 - precision_1: 0.9299 - recall_1: 0.9403 - val_loss: 0.3977 - val_accuracy: 0.9074 - val_precision_1: 0.9747 - val_recall_1: 0.8365\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - 81s 402ms/step - loss: 0.2718 - accuracy: 0.9419 - precision_1: 0.9355 - recall_1: 0.9493 - val_loss: 0.4327 - val_accuracy: 0.8672 - val_precision_1: 0.9900 - val_recall_1: 0.7419\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - 81s 405ms/step - loss: 0.2110 - accuracy: 0.9490 - precision_1: 0.9435 - recall_1: 0.9552 - val_loss: 0.2514 - val_accuracy: 0.9250 - val_precision_1: 0.9783 - val_recall_1: 0.8692\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - 81s 403ms/step - loss: 0.1848 - accuracy: 0.9533 - precision_1: 0.9490 - recall_1: 0.9581 - val_loss: 0.8882 - val_accuracy: 0.6062 - val_precision_1: 0.9995 - val_recall_1: 0.2126\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - 81s 405ms/step - loss: 0.1588 - accuracy: 0.9605 - precision_1: 0.9584 - recall_1: 0.9627 - val_loss: 0.1921 - val_accuracy: 0.9320 - val_precision_1: 0.8957 - val_recall_1: 0.9778\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - 81s 403ms/step - loss: 0.1404 - accuracy: 0.9646 - precision_1: 0.9636 - recall_1: 0.9656 - val_loss: 0.2784 - val_accuracy: 0.9217 - val_precision_1: 0.9819 - val_recall_1: 0.8592\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - 81s 405ms/step - loss: 0.1231 - accuracy: 0.9704 - precision_1: 0.9695 - recall_1: 0.9713 - val_loss: 0.1682 - val_accuracy: 0.9449 - val_precision_1: 0.9306 - val_recall_1: 0.9616\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - 81s 404ms/step - loss: 0.1107 - accuracy: 0.9733 - precision_1: 0.9743 - recall_1: 0.9722 - val_loss: 0.4991 - val_accuracy: 0.8734 - val_precision_1: 0.8004 - val_recall_1: 0.9947\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - 82s 407ms/step - loss: 0.0935 - accuracy: 0.9798 - precision_1: 0.9803 - recall_1: 0.9792 - val_loss: 0.3804 - val_accuracy: 0.8991 - val_precision_1: 0.9909 - val_recall_1: 0.8056\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - 81s 403ms/step - loss: 0.0844 - accuracy: 0.9814 - precision_1: 0.9826 - recall_1: 0.9801 - val_loss: 0.2315 - val_accuracy: 0.9403 - val_precision_1: 0.9704 - val_recall_1: 0.9083\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - 81s 404ms/step - loss: 0.0776 - accuracy: 0.9836 - precision_1: 0.9850 - recall_1: 0.9822 - val_loss: 0.3548 - val_accuracy: 0.9297 - val_precision_1: 0.8868 - val_recall_1: 0.9850\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - 81s 406ms/step - loss: 0.0681 - accuracy: 0.9865 - precision_1: 0.9881 - recall_1: 0.9848 - val_loss: 0.2418 - val_accuracy: 0.9518 - val_precision_1: 0.9524 - val_recall_1: 0.9512\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - 81s 403ms/step - loss: 0.0606 - accuracy: 0.9884 - precision_1: 0.9900 - recall_1: 0.9868 - val_loss: 0.2021 - val_accuracy: 0.9507 - val_precision_1: 0.9611 - val_recall_1: 0.9395\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - 82s 407ms/step - loss: 0.0573 - accuracy: 0.9895 - precision_1: 0.9912 - recall_1: 0.9877 - val_loss: 0.2962 - val_accuracy: 0.9446 - val_precision_1: 0.9729 - val_recall_1: 0.9147\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - 81s 404ms/step - loss: 0.0511 - accuracy: 0.9912 - precision_1: 0.9923 - recall_1: 0.9902 - val_loss: 0.2173 - val_accuracy: 0.9401 - val_precision_1: 0.9786 - val_recall_1: 0.8998\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - 81s 402ms/step - loss: 0.0511 - accuracy: 0.9915 - precision_1: 0.9934 - recall_1: 0.9896 - val_loss: 0.3450 - val_accuracy: 0.9093 - val_precision_1: 0.9883 - val_recall_1: 0.8285\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - 81s 405ms/step - loss: 0.0453 - accuracy: 0.9923 - precision_1: 0.9938 - recall_1: 0.9908 - val_loss: 0.2374 - val_accuracy: 0.9489 - val_precision_1: 0.9659 - val_recall_1: 0.9308\n",
            "Transfer Learning training finished.\n"
          ]
        }
      ],
      "source": [
        "# Train the Transfer Learning model\n",
        "print(\"Starting training with Transfer Learning using Net...\")\n",
        "ResNet_model_history = Net_model.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = 100,\n",
        "    verbose = 1,\n",
        "    callbacks = [early_stopping]\n",
        ")\n",
        "print(\"Transfer Learning training finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-01-31T05:17:58.700763Z",
          "iopub.status.busy": "2024-01-31T05:17:58.700413Z",
          "iopub.status.idle": "2024-01-31T05:18:03.265048Z",
          "shell.execute_reply": "2024-01-31T05:18:03.264168Z",
          "shell.execute_reply.started": "2024-01-31T05:17:58.700722Z"
        },
        "id": "hxDngpl-nnMN",
        "outputId": "9ee939c1-cca2-4c84-f567-fc3109c231be",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "40/40 [==============================] - 4s 103ms/step - loss: 0.1682 - accuracy: 0.9449 - precision_1: 0.9306 - recall_1: 0.9616\n",
            "Val Loss: 0.1682\n",
            "Val Accuracy: 0.9449\n",
            "Val Precision: 0.9306\n",
            "Val Recall: 0.9616\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test dataset\n",
        "val_loss, val_accuracy, val_precision, val_recall = Net_model.evaluate(val_ds)\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Val Loss: {val_loss:.4f}\")\n",
        "print(f\"Val Accuracy: {val_accuracy:.4f}\")\n",
        "print(f\"Val Precision: {val_precision:.4f}\")\n",
        "print(f\"Val Recall: {val_recall:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-31T05:18:40.234071Z",
          "iopub.status.busy": "2024-01-31T05:18:40.233716Z",
          "iopub.status.idle": "2024-01-31T05:18:41.273523Z",
          "shell.execute_reply": "2024-01-31T05:18:41.272628Z",
          "shell.execute_reply.started": "2024-01-31T05:18:40.234043Z"
        },
        "id": "lmHGGU9NnnMN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Plot error rates and metric rates\n",
        "plot_metrics(ResNet_model_history, 'loss')\n",
        "plot_metrics(ResNet_model_history, 'accuracy')\n",
        "plot_metrics(ResNet_model_history, 'precision')\n",
        "plot_metrics(ResNet_model_history, 'recall')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 3041726,
          "sourceId": 5256696,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30646,
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
